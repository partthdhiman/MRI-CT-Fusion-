# -*- coding: utf-8 -*-
"""genai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rlP1C0uEom_FHCM315qw8YeWqkXJkLfn
"""

!pip install -q pydicom nibabel pillow tqdm matplotlib torch torchvision scikit-image

!wget https://www.kaggle.com/api/v1/datasets/download/omarxadel/chaos-combined-ct-mr-healthy-abdominal-organ -O chaos.zip

!unzip chaos.zip -d chaos_dataset

import os, itertools, textwrap
from glob import glob
ROOT = "chaos_dataset"

ct_folders = sorted([p for p in glob(f"{ROOT}/**/CT/*", recursive=True) if os.path.isdir(p)])
mr_folders = sorted([p for p in glob(f"{ROOT}/**/MR/*", recursive=True) if os.path.isdir(p)])

print("Total CT folders found:", len(ct_folders))
print("Total MR folders found:", len(mr_folders))
print("\nFirst 20 CT folder names:")
for p in itertools.islice(ct_folders, 20):
    print(" CT:", os.path.basename(p), " <-- full:", p)

print("\nFirst 20 MR folder names:")
for p in itertools.islice(mr_folders, 20):
    print(" MR:", os.path.basename(p), " <-- full:", p)

import os, re, math
from glob import glob
from pathlib import Path
import numpy as np
from PIL import Image
import pydicom
import nibabel as nib

ROOT = "chaos_dataset"
OUT_MRI = "dataset/mri"
OUT_CT = "dataset/ct"
SIZE = (256,256)

os.makedirs(OUT_MRI, exist_ok=True)
os.makedirs(OUT_CT, exist_ok=True)

def list_patient_folders(root, modality_name):
    pattern = f"{root}/**/{modality_name}/*"
    paths = sorted([p for p in glob(pattern, recursive=True) if os.path.isdir(p)])
    return paths

ct_folders = list_patient_folders(ROOT, "CT")
mr_folders = list_patient_folders(ROOT, "MR")

print("Found CT folders:", len(ct_folders))
print("Found MR folders:", len(mr_folders))

def numeric_key(s):
    nums = re.findall(r"\d+", s)
    return nums[0] if nums else os.path.basename(s).lower()


ct_map = {}
for p in ct_folders:
    k = numeric_key(os.path.basename(p))
    ct_map.setdefault(k, []).append(p)
mr_map = {}
for p in mr_folders:
    k = numeric_key(os.path.basename(p))
    mr_map.setdefault(k, []).append(p)

print("\nSample CT keys (key: count):")
for i,(k,v) in enumerate(ct_map.items()):
    if i>9: break
    print(k, len(v))
print("\nSample MR keys (key: count):")
for i,(k,v) in enumerate(mr_map.items()):
    if i>9: break
    print(k, len(v))

common_keys = sorted(set(ct_map.keys()).intersection(set(mr_map.keys())))
pairs = []
if common_keys:
    for k in common_keys:
        pairs.append((ct_map[k][0], mr_map[k][0], k))
else:
    minlen = min(len(ct_folders), len(mr_folders))
    for i in range(minlen):
        pairs.append((ct_folders[i], mr_folders[i], f"fallback_{i}"))

print(f"\nPaired patients by key: {len(pairs)} (examples):")
for a,b,k in pairs[:8]:
    print(" key:", k, " CT:", os.path.basename(a), " MR:", os.path.basename(b))
def read_dicom_series(folder):
    files = sorted(glob(str(Path(folder) / "*.dcm")))
    if not files:
        files = sorted(glob(str(Path(folder) / "**" / "*.dcm"), recursive=True))
    slices = []
    for f in files:
        try:
            d = pydicom.dcmread(f)
            arr = d.pixel_array.astype(np.float32)
            arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)
            arr = (arr * 255).astype(np.uint8)
            slices.append(arr)
        except Exception as e:
            continue
    return slices

def read_nifti_file(pth):
    try:
        img = nib.load(pth)
        data = img.get_fdata()
        if data.ndim == 3:
            axis = int(np.argmax(data.shape))
            slices = []
            if axis == 0:
                for i in range(data.shape[0]):
                    slices.append(np.array(data[i,:,:]))
            elif axis == 1:
                for i in range(data.shape[1]):
                    slices.append(np.array(data[:,i,:]))
            else:
                for i in range(data.shape[2]):
                    slices.append(np.array(data[:,:,i]))
            slices_u = []
            for s in slices:
                a = s.astype(np.float32)
                a = (a - a.min()) / (a.max() - a.min() + 1e-8)
                a = (a * 255).astype(np.uint8)
                slices_u.append(a)
            return slices_u
    except Exception as e:
        return []
    return []

counter = 1
skipped = 0
for ct_folder, mr_folder, key in pairs:
    ct_slices = []
    ct_niftis = sorted(glob(os.path.join(ct_folder, "*.nii")) + glob(os.path.join(ct_folder, "*.nii.gz")))
    if ct_niftis:
        ct_slices = read_nifti_file(ct_niftis[0])
    else:
        ct_slices = read_dicom_series(ct_folder)
    mr_slices = []
    mr_niftis = sorted(glob(os.path.join(mr_folder, "*.nii")) + glob(os.path.join(mr_folder, "*.nii.gz")))
    if mr_niftis:
        mr_slices = read_nifti_file(mr_niftis[0])
    else:
        mr_slices = read_dicom_series(mr_folder)

    if not ct_slices or not mr_slices:
        skipped += 1
        continue

    L = min(len(ct_slices), len(mr_slices))
    if L == 0:
        skipped += 1
        continue

    for i in range(L):
        try:
            ct_img = Image.fromarray(ct_slices[i]).convert("L").resize(SIZE)
            mr_img = Image.fromarray(mr_slices[i]).convert("L").resize(SIZE)
            ct_img.save(f"{OUT_CT}/{counter:05d}.png")
            mr_img.save(f"{OUT_MRI}/{counter:05d}.png")
            if counter <= 6:
                print("Saved example:", f"{counter:05d}.png from key {key}")
            counter += 1
        except Exception as e:
            # skip malformed slices
            continue

print(f"\nDone. Saved {counter-1} paired slices. Skipped pairs: {skipped}")

!ls -la dataset/mri | head -n 30
!ls -la dataset/ct  | head -n 30
print("MRI count:", len(os.listdir("dataset/mri")))
print("CT count:", len(os.listdir("dataset/ct")))

import os, shutil
os.makedirs("dataset_train/mri", exist_ok=True)
os.makedirs("dataset_train/ct", exist_ok=True)
os.makedirs("dataset_test/mri", exist_ok=True)
os.makedirs("dataset_test/ct", exist_ok=True)

files = sorted(os.listdir("dataset/mri"))

assert len(files) == len(os.listdir("dataset/ct"))
total = len(files)
split_point = total // 2   # EXACT 50%

train_files = files[:split_point]
test_files  = files[split_point:]

# Copy files
for f in train_files:
    shutil.copy(f"dataset/mri/{f}", f"dataset_train/mri/{f}")
    shutil.copy(f"dataset/ct/{f}",  f"dataset_train/ct/{f}")

for f in test_files:
    shutil.copy(f"dataset/mri/{f}", f"dataset_test/mri/{f}")
    shutil.copy(f"dataset/ct/{f}",  f"dataset_test/ct/{f}")

print("DONE SPLIT")
print("Train MRI:", len(os.listdir("dataset_train/mri")))
print("Test MRI :", len(os.listdir("dataset_test/mri")))
print("Train CT :", len(os.listdir("dataset_train/ct")))
print("Test CT  :", len(os.listdir("dataset_test/ct")))

import os
from glob import glob

print("Checking folders...")
for p in ["dataset_train/mri","dataset_train/ct","dataset_test/mri","dataset_test/ct"]:
    print(p, "->", os.path.exists(p), "count:", len(os.listdir(p)) if os.path.exists(p) else 0)

os.makedirs("results/visual_check", exist_ok=True)

# visualize random samples and save
import random, numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim

def norm_arr(pil):
    a = np.array(pil).astype(np.float32)
    a = (a - a.min()) / (a.max() - a.min() + 1e-8)
    return a

def show_and_save_examples(root_mri, root_ct, tag, n=5, start_index=None):
    m_files = sorted(os.listdir(root_mri))
    if start_index is None:
        samples = random.sample(m_files, min(n, len(m_files)))
    else:
        samples = m_files[start_index:start_index+n]
    stats = []
    for i,fn in enumerate(samples):
        mpath = os.path.join(root_mri, fn)
        cpath = os.path.join(root_ct, fn)
        if not os.path.exists(mpath) or not os.path.exists(cpath):
            continue
        m = Image.open(mpath).convert("L")
        c = Image.open(cpath).convert("L")
        ma = norm_arr(m); ca = norm_arr(c)
        fused = (ma + ca) / 2.0
        outfn = f"results/visual_check/{tag}_{fn}"
        Image.fromarray((ma*255).astype("uint8")).save(outfn.replace(".png","_mri.png"))
        Image.fromarray((ca*255).astype("uint8")).save(outfn.replace(".png","_ct.png"))
        Image.fromarray((fused*255).astype("uint8")).save(outfn.replace(".png","_avgfused.png"))
        stats.append({
            "fname": fn,
            "m_mean": float(ma.mean()), "c_mean": float(ca.mean()), "f_mean": float(fused.mean()),
            "m_std": float(ma.std()), "c_std": float(ca.std()), "f_std": float(fused.std()),
            "psnr_avg": float(psnr((ma+ca)/2.0, fused, data_range=1.0)),  
            "ssim_avg": float(ssim((ma+ca)/2.0, fused, data_range=1.0))
        })
        # display grid
        plt.figure(figsize=(9,3))
        plt.subplot(1,3,1); plt.imshow(ma, cmap="gray"); plt.title("MRI"); plt.axis("off")
        plt.subplot(1,3,2); plt.imshow(ca, cmap="gray"); plt.title("CT"); plt.axis("off")
        plt.subplot(1,3,3); plt.imshow(fused, cmap="gray"); plt.title("Avg Fused"); plt.axis("off")
        plt.suptitle(f"{tag} sample {i+1}: {fn}")
        plt.show()
    return stats

print("Showing 5 random TRAIN samples:")
train_stats = show_and_save_examples("dataset_train/mri","dataset_train/ct","train", n=5)
print("Showing 5 random TEST samples:")
test_stats  = show_and_save_examples("dataset_test/mri","dataset_test/ct","test", n=5)

import pandas as pd
print("\nTrain sample stats:")
display(pd.DataFrame(train_stats))
print("\nTest sample stats:")
display(pd.DataFrame(test_stats))

print("Saved images under results/visual_check/*.png")

import os, random
from glob import glob
from pathlib import Path

import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torchvision.utils import save_image
from tqdm import tqdm
# CONFIG
TRAIN_ROOT = "dataset_train"
TEST_ROOT = "dataset_test"
SAVE_DIR = "checkpoints_fusion"
os.makedirs(SAVE_DIR, exist_ok=True)

IMG_SIZE = 256
BATCH_SIZE = 6
LR = 2e-4
NUM_EPOCHS = 10
NUM_WORKERS = 2
REFINEMENT_STEPS = 2 
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# DATASET
class PairedDataset(Dataset):
    def __init__(self, root, size=256):
        self.root_m = Path(root)/"mri"
        self.root_c = Path(root)/"ct"

        mlist = sorted(os.listdir(self.root_m))
        clist = sorted(os.listdir(self.root_c))

        self.files = sorted(list(set(mlist).intersection(clist)))
        if len(self.files) == 0:
            raise ValueError("No paired files found!!!")

        self.size = size
        self.tf = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.5],[0.5])
        ])

    def __len__(self): return len(self.files)

    def __getitem__(self, idx):
        fn = self.files[idx]

        m = Image.open(self.root_m/fn).convert("L").resize((self.size,self.size))
        c = Image.open(self.root_c/fn).convert("L").resize((self.size,self.size))

        mt = self.tf(m)
        ct = self.tf(c)

        inp = torch.cat([mt, ct], dim=0)  

        return inp, mt, ct, fn


# MODEL COMPONENTS

def conv_block(in_ch, out_ch):
    return nn.Sequential(
        nn.Conv2d(in_ch, out_ch, 3, padding=1),
        nn.BatchNorm2d(out_ch),
        nn.LeakyReLU(0.2, inplace=True)
    )

class ChannelAttention(nn.Module):
    def __init__(self, ch):
        super().__init__()
        self.avg = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(ch, ch//8),
            nn.ReLU(),
            nn.Linear(ch//8, ch),
            nn.Sigmoid()
        )

    def forward(self,x):
        b,c,_,_ = x.size()
        y = self.avg(x).view(b,c)
        y = self.fc(y).view(b,c,1,1)
        return x * y

class UNetGenerator(nn.Module):
    def __init__(self,in_channels=2,out_channels=1,base=32):
        super().__init__()
        self.e1 = conv_block(in_channels, base)
        self.e2 = conv_block(base, base*2)
        self.e3 = conv_block(base*2, base*4)
        self.e4 = conv_block(base*4, base*8)

        self.pool = nn.MaxPool2d(2,2)
        self.bottleneck = conv_block(base*8, base*16)

        self.up4 = nn.ConvTranspose2d(base*16, base*8,2,2)
        self.d4 = conv_block(base*16, base*8)

        self.up3 = nn.ConvTranspose2d(base*8, base*4,2,2)
        self.d3 = conv_block(base*8, base*4)

        self.up2 = nn.ConvTranspose2d(base*4, base*2,2,2)
        self.d2 = conv_block(base*4, base*2)

        self.up1 = nn.ConvTranspose2d(base*2, base,2,2)
        self.d1 = conv_block(base*2, base)

        self.final = nn.Sequential(
            nn.Conv2d(base, out_channels, 3, padding=1),
            nn.Tanh()
        )

    def forward(self,x):
        e1 = self.e1(x)
        e2 = self.e2(self.pool(e1))
        e3 = self.e3(self.pool(e2))
        e4 = self.e4(self.pool(e3))

        b = self.bottleneck(self.pool(e4))

        d4 = self.up4(b)
        d4 = torch.cat([d4,e4], dim=1)
        d4 = self.d4(d4)

        d3 = self.up3(d4)
        d3 = torch.cat([d3,e3], dim=1)
        d3 = self.d3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2,e2], dim=1)
        d2 = self.d2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1,e1], dim=1)
        d1 = self.d1(d1)

        return self.final(d1)

class PatchDiscriminator(nn.Module):
    def __init__(self,in_ch=1,base=32):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, base, 4,2,1), nn.LeakyReLU(0.2),
            conv_block(base, base*2),
            conv_block(base*2, base*4),
            conv_block(base*4, base*8),
            nn.Conv2d(base*8, 1, 4,1,1)
        )
    def forward(self,x): return self.net(x)

class RefinementNet(nn.Module):
    def __init__(self,in_ch=1):
        super().__init__()
        self.c1 = conv_block(in_ch,32)
        self.c2 = conv_block(32,64)
        self.c3 = conv_block(64,128)
        self.p = nn.MaxPool2d(2,2)
        self.u2 = nn.ConvTranspose2d(128,64,2,2)
        self.d2 = conv_block(128,64)
        self.u1 = nn.ConvTranspose2d(64,32,2,2)
        self.d1 = conv_block(64,32)
        self.fin = nn.Conv2d(32,1,3,padding=1)

    def forward(self,x):
        e1 = self.c1(x)
        e2 = self.c2(self.p(e1))
        e3 = self.c3(self.p(e2))
        d2 = self.u2(e3)
        d2 = torch.cat([d2,e2],1)
        d2 = self.d2(d2)
        d1 = self.u1(d2)
        d1 = torch.cat([d1,e1],1)
        d1 = self.d1(d1)
        return self.fin(d1)

def refine_iter(refine, fused, steps=REFINEMENT_STEPS):
    x = fused
    for s in range(steps):
        noise = torch.randn_like(x)*0.02
        den = refine(x+noise)
        x = x + torch.tanh(den)*0.5
        x = x.clamp(-1,1)
    return x

# LOSSES

def hinge_d(real, fake):
    return 0.5*(torch.mean(F.relu(1-real)) + torch.mean(F.relu(1+fake)))

def hinge_g(fake):
    return -torch.mean(fake)

class PerceptualLoss(nn.Module):
    def __init__(self):
        super().__init__()
        vgg = models.vgg16(weights=models.VGG16_Weights.DEFAULT).features[:16]
        self.vgg = vgg.eval().to(DEVICE)
        for p in self.vgg.parameters(): p.requires_grad=False
        self.l1 = nn.L1Loss()

    def forward(self,pred,target):
        # convert gray → 3 channel
        pred3 = pred.repeat(1,3,1,1)
        targ3 = target.repeat(1,3,1,1)
        return self.l1(self.vgg(pred3), self.vgg(targ3))

# TRAINING SETUP

gen = UNetGenerator().to(DEVICE)
disc = PatchDiscriminator().to(DEVICE)
refine = RefinementNet().to(DEVICE)
perc = PerceptualLoss().to(DEVICE)

opt_g = torch.optim.Adam(list(gen.parameters())+list(refine.parameters()), lr=LR, betas=(0.5,0.999))
opt_d = torch.optim.Adam(disc.parameters(), lr=LR, betas=(0.5,0.999))

l1 = nn.L1Loss()

train_ds = PairedDataset(TRAIN_ROOT, size=IMG_SIZE)
test_ds = PairedDataset(TEST_ROOT, size=IMG_SIZE)
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)

print("Train samples:", len(train_ds))
print("Test samples :", len(test_ds))
# TRAIN LOOP
for epoch in range(1, NUM_EPOCHS+1):
    gen.train(); disc.train(); refine.train()

    pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{NUM_EPOCHS}")
    for inp, mt, ct, fn in pbar:
        inp, mt, ct = inp.to(DEVICE), mt.to(DEVICE), ct.to(DEVICE)
        target = (mt+ct)*0.5

        # ---- Train D ----
        with torch.no_grad():
            fused0 = gen(inp)
            fused = refine_iter(refine, fused0)
        real = disc(target)
        fake = disc(fused.detach())
        d_loss = hinge_d(real, fake)
        opt_d.zero_grad()
        d_loss.backward()
        opt_d.step()

        # ---- Train G ----
        fused0 = gen(inp)
        fused = refine_iter(refine, fused0)
        fake_g = disc(fused)
        adv = hinge_g(fake_g)
        r_loss = l1(fused, target)
        p_loss = perc(fused, target)
        total = r_loss + 0.1*p_loss + 0.01*adv

        opt_g.zero_grad()
        total.backward()
        opt_g.step()

        pbar.set_postfix({"DL":float(d_loss),"GL":float(total)})

    # Save checkpoint
    torch.save({
        "gen":gen.state_dict(),
        "refine":refine.state_dict(),
        "disc":disc.state_dict(),
        "epoch":epoch
    }, f"{SAVE_DIR}/epoch_{epoch}.pth")

    print("Saved checkpoint for epoch",epoch)

print("Training completed.")

import os, sys, torch, numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
import torch.nn as nn
import torch.nn.functional as F

# Config / checkpoint
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
CKPT = "checkpoints_fusion/epoch_10.pth"
OUT_DIR = "results/test_fused"
os.makedirs(OUT_DIR, exist_ok=True)

# Model classes (copied from training script)
def conv_block(in_ch, out_ch):
    return nn.Sequential(
        nn.Conv2d(in_ch, out_ch, 3, padding=1),
        nn.BatchNorm2d(out_ch),
        nn.LeakyReLU(0.2, inplace=True)
    )

class UNetGenerator(nn.Module):
    def __init__(self,in_channels=2,out_channels=1,base=32):
        super().__init__()
        self.e1 = conv_block(in_channels, base)
        self.e2 = conv_block(base, base*2)
        self.e3 = conv_block(base*2, base*4)
        self.e4 = conv_block(base*4, base*8)

        self.pool = nn.MaxPool2d(2,2)
        self.bottleneck = conv_block(base*8, base*16)

        self.up4 = nn.ConvTranspose2d(base*16, base*8,2,2)
        self.d4 = conv_block(base*16, base*8)

        self.up3 = nn.ConvTranspose2d(base*8, base*4,2,2)
        self.d3 = conv_block(base*8, base*4)

        self.up2 = nn.ConvTranspose2d(base*4, base*2,2,2)
        self.d2 = conv_block(base*4, base*2)

        self.up1 = nn.ConvTranspose2d(base*2, base,2,2)
        self.d1 = conv_block(base*2, base)

        self.final = nn.Sequential(
            nn.Conv2d(base, out_channels, 3, padding=1),
            nn.Tanh()
        )

    def forward(self,x):
        e1 = self.e1(x)
        e2 = self.e2(self.pool(e1))
        e3 = self.e3(self.pool(e2))
        e4 = self.e4(self.pool(e3))

        b = self.bottleneck(self.pool(e4))

        d4 = self.up4(b)
        d4 = torch.cat([d4,e4], dim=1)
        d4 = self.d4(d4)

        d3 = self.up3(d4)
        d3 = torch.cat([d3,e3], dim=1)
        d3 = self.d3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2,e2], dim=1)
        d2 = self.d2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1,e1], dim=1)
        d1 = self.d1(d1)

        return self.final(d1)

class RefinementNet(nn.Module):
    def __init__(self,in_ch=1):
        super().__init__()
        self.c1 = conv_block(in_ch,32)
        self.c2 = conv_block(32,64)
        self.c3 = conv_block(64,128)
        self.p = nn.MaxPool2d(2,2)
        self.u2 = nn.ConvTranspose2d(128,64,2,2)
        self.d2 = conv_block(128,64)
        self.u1 = nn.ConvTranspose2d(64,32,2,2)
        self.d1 = conv_block(64,32)
        self.fin = nn.Conv2d(32,1,3,padding=1)

    def forward(self,x):
        e1 = self.c1(x)
        e2 = self.c2(self.p(e1))
        e3 = self.c3(self.p(e2))
        d2 = self.u2(e3)
        d2 = torch.cat([d2,e2],1)
        d2 = self.d2(d2)
        d1 = self.u1(d2)
        d1 = torch.cat([d1,e1],1)
        d1 = self.d1(d1)
        return self.fin(d1)


# Utility: refinement loop (same logic as training)
def refine_iter(refine, fused, steps=4):
    x = fused
    for s in range(steps):
        noise = torch.randn_like(x) * 0.02
        den = refine(x + noise)
        x = x + torch.tanh(den) * 0.5
        x = x.clamp(-1, 1)
    return x
# Load checkpoint & models
ck = torch.load(CKPT, map_location=DEVICE)
gen = UNetGenerator().to(DEVICE)
refine = RefinementNet().to(DEVICE)
gen.load_state_dict(ck["gen"])
refine.load_state_dict(ck["refine"])
gen.eval(); refine.eval()

# Transforms (must match training)
tf = transforms.Compose([
    transforms.Resize((256,256)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Inference function (uses refinement steps = 2)
REFINEMENT_STEPS_INFER = 2

def infer_pair(mri_path, ct_path):
    m = Image.open(mri_path).convert("L")
    c = Image.open(ct_path).convert("L")
    mt = tf(m).unsqueeze(0).to(DEVICE)
    ct = tf(c).unsqueeze(0).to(DEVICE)

    inp = torch.cat([mt, ct], dim=1)

    with torch.no_grad():
        fused0 = gen(inp)
        fused = refine_iter(refine, fused0, steps=REFINEMENT_STEPS_INFER)
        fused = fused.clamp(-1, 1)


    fused01 = (fused + 1.0) / 2.0
    fused_np = fused01.squeeze(0).squeeze(0).cpu().numpy()
    fused_img = (np.clip(fused_np, 0.0, 1.0) * 255.0).astype("uint8")
    return m.resize((256,256)), c.resize((256,256)), Image.fromarray(fused_img)
# Run over test set
test_mri_files = sorted(os.listdir("dataset_test/mri"))
saved = []
for fn in test_mri_files:
    m_path = os.path.join("dataset_test/mri", fn)
    c_path = os.path.join("dataset_test/ct", fn)
    try:
        m_img, c_img, fused_img = infer_pair(m_path, c_path)
        outfn = os.path.join(OUT_DIR, fn)
        fused_img.save(outfn)
        saved.append(outfn)
    except Exception as e:
        print("skip", fn, e)

print("Saved fused images:", len(saved), "to", OUT_DIR)
# Display first 6 examples
for p in saved[:6]:
    fn = os.path.basename(p)
    m = Image.open(os.path.join("dataset_test/mri", fn)).resize((256,256))
    c = Image.open(os.path.join("dataset_test/ct", fn)).resize((256,256))
    fimg = Image.open(p)
    plt.figure(figsize=(9,3))
    plt.subplot(1,3,1); plt.imshow(m, cmap="gray"); plt.title("MRI"); plt.axis("off")
    plt.subplot(1,3,2); plt.imshow(c, cmap="gray"); plt.title("CT"); plt.axis("off")
    plt.subplot(1,3,3); plt.imshow(fimg, cmap="gray"); plt.title("Fused"); plt.axis("off")
    plt.show()

# METRICS: PSNR, SSIM, Entropy, Edge-preservation (Sobel)
import os, csv, numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim
from skimage.filters import sobel
from PIL import Image
import math
import glob

def load_norm_arr(path):
    a = np.array(Image.open(path).convert("L")).astype(np.float32)
    a = (a - a.min()) / (a.max() - a.min() + 1e-8)
    return a

out_csv = "results/metrics_test.csv"
fns = sorted(os.listdir("results/test_fused"))
rows = []
for fn in fns:
    fused_path = os.path.join("results/test_fused", fn)
    m = load_norm_arr(os.path.join("dataset_test/mri", fn))
    c = load_norm_arr(os.path.join("dataset_test/ct", fn))
    fused = load_norm_arr(fused_path)
    # proxy target:
    target = (m + c) / 2.0
    # compute PSNR/SSIM (data_range=1.0)
    ps = psnr(target, fused, data_range=1.0)
    ss = ssim(target, fused, data_range=1.0)
    # entropy
    hist, _ = np.histogram(fused.flatten(), bins=256, range=(0,1), density=True)
    hist = hist + 1e-12
    ent = -np.sum(hist * np.log2(hist))
    # edge preservation: compare sobel maps (correlation)
    s_t = sobel(target)
    s_f = sobel(fused)
    # normalized cross-correlation
    num = np.sum((s_t - s_t.mean())*(s_f - s_f.mean()))
    den = np.sqrt(np.sum((s_t - s_t.mean())**2) * np.sum((s_f - s_f.mean())**2) + 1e-12)
    edge_corr = num/den
    rows.append([fn, ps, ss, ent, float(edge_corr)])
# save csv
with open(out_csv, "w", newline="") as csvf:
    writer = csv.writer(csvf)
    writer.writerow(["fname","psnr","ssim","entropy","edge_corr"])
    writer.writerows(rows)

# print summary stats
ps_list = [r[1] for r in rows]
ss_list = [r[2] for r in rows]
print("PSNR mean/median:", np.nanmean(ps_list), np.nanmedian(ps_list))
print("SSIM mean/median:", np.nanmean(ss_list), np.nanmedian(ss_list))
print("Saved metrics to", out_csv)

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import os

def avg_fuse(m_path, c_path):
    m = np.array(Image.open(m_path).convert("L")).astype(np.float32)
    c = np.array(Image.open(c_path).convert("L")).astype(np.float32)

    # normalize both to [0,1]
    m = (m - m.min())/(m.max()-m.min()+1e-8)
    c = (c - c.min())/(c.max()-c.min()+1e-8)

    avg = (m + c) / 2.0
    return avg

saved = sorted(os.listdir("results/test_fused"))[:10]

OUT_DIR_AVG = "results/test_avg"
os.makedirs(OUT_DIR_AVG, exist_ok=True)

OUT_DIR_COMBO = "results/test_comparison"
os.makedirs(OUT_DIR_COMBO, exist_ok=True)

for fn in saved:
    m_p = f"dataset_test/mri/{fn}"
    c_p = f"dataset_test/ct/{fn}"

    # ----- compute avg fused -----
    avg = avg_fuse(m_p, c_p)                    # float [0,1]
    avg_uint8 = (avg * 255).astype(np.uint8)    # convert to image
    avg_img = Image.fromarray(avg_uint8)

    # ----- save avg result -----
    avg_img.save(f"{OUT_DIR_AVG}/{fn}")

    # ----- load GAN fused output -----
    gan = np.array(Image.open(f"results/test_fused/{fn}").convert("L")).astype(np.float32) / 255.0

    # ----- optionally, save side-by-side comparison -----
    side_by_side = np.hstack([avg, gan])
    side_by_side_uint8 = (side_by_side * 255).astype(np.uint8)
    Image.fromarray(side_by_side_uint8).save(f"{OUT_DIR_COMBO}/{fn}")

    # ----- plot output -----
    plt.figure(figsize=(12,4))
    plt.subplot(1,3,1); plt.imshow(Image.open(m_p).convert("L"), cmap="gray"); plt.title("MRI"); plt.axis("off")
    plt.subplot(1,3,2); plt.imshow(Image.open(c_p).convert("L"), cmap="gray"); plt.title("CT"); plt.axis("off")
    plt.subplot(1,3,3); plt.imshow(side_by_side, cmap="gray"); plt.title("Avg | GAN"); plt.axis("off")
    plt.show()

print("Saved AVG fusion results to:", OUT_DIR_AVG)
print("Saved comparison images to:", OUT_DIR_COMBO)

#compute PSNR, SSIM, Entropy, Edge-corr and save CSV
import os, csv, numpy as np
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim
from skimage.filters import sobel

def load_norm(path):
    a = np.array(Image.open(path).convert("L")).astype(np.float32)
    a = (a - a.min())/(a.max() - a.min() + 1e-8)
    return a

fused_dir = "results/test_fused"
out_csv = "results/metrics_full_test.csv"
files = sorted(os.listdir(fused_dir))
rows = []
for fn in files:
    fused = load_norm(os.path.join(fused_dir, fn))
    mri = load_norm(os.path.join("dataset_test/mri", fn))
    ct  = load_norm(os.path.join("dataset_test/ct", fn))
    target = (mri + ct)/2.0
    p = psnr(target, fused, data_range=1.0)
    s = ssim(target, fused, data_range=1.0)
    # entropy
    hist, _ = np.histogram(fused.flatten(), bins=256, range=(0,1), density=True)
    hist = hist + 1e-12
    ent = -np.sum(hist * np.log2(hist))
    # edge correlation (sobel)
    s_t = sobel(target)
    s_f = sobel(fused)
    num = np.sum((s_t - s_t.mean())*(s_f - s_f.mean()))
    den = np.sqrt(np.sum((s_t - s_t.mean())**2) * np.sum((s_f - s_f.mean())**2) + 1e-12)
    edge_corr = num/den
    rows.append([fn, float(p), float(s), float(ent), float(edge_corr)])

# save csv
os.makedirs("results", exist_ok=True)
with open(out_csv, "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["fname","psnr","ssim","entropy","edge_corr"])
    writer.writerows(rows)

# summary
ps = np.array([r[1] for r in rows])
ss = np.array([r[2] for r in rows])
ent = np.array([r[3] for r in rows])
ec = np.array([r[4] for r in rows])
print("Saved metrics:", out_csv)
print("PSNR mean/median/std:", ps.mean(), np.median(ps), ps.std())
print("SSIM mean/median/std:", ss.mean(), np.median(ss), ss.std())
print("Entropy mean/median:", ent.mean(), np.median(ent))
print("EdgeCorr mean/median:", ec.mean(), np.median(ec))

import os, csv, numpy as np
import matplotlib.pyplot as plt
import json

# New directory
PLOT_DIR = "results/plot_results"
os.makedirs(PLOT_DIR, exist_ok=True)

csv_path = "results/metrics_full_test.csv"
data = []

# Load CSV
with open(csv_path) as f:
    rows = list(csv.reader(f))
    header = rows[0]
    for r in rows[1:]:
        data.append(r)

data = np.array(data)

fnames = data[:,0]
ps = data[:,1].astype(float)
ss = data[:,2].astype(float)
ent = data[:,3].astype(float)
ec = data[:,4].astype(float)

# -----------------------
# Histogram: PSNR
# -----------------------
plt.figure(figsize=(6,4))
plt.hist(ps, bins=40)
plt.title("PSNR distribution (test set)")
plt.xlabel("PSNR")
plt.ylabel("Count")
plt.tight_layout()
plt.savefig(f"{PLOT_DIR}/psnr_hist.png")
plt.show()

# -----------------------
# Histogram: SSIM
# -----------------------
plt.figure(figsize=(6,4))
plt.hist(ss, bins=40)
plt.title("SSIM distribution (test set)")
plt.xlabel("SSIM")
plt.ylabel("Count")
plt.tight_layout()
plt.savefig(f"{PLOT_DIR}/ssim_hist.png")
plt.show()

# -----------------------
# Boxplot
# -----------------------
plt.figure(figsize=(6,4))
plt.boxplot([ps, ss], labels=["PSNR", "SSIM"])
plt.title("Boxplot: PSNR and SSIM")
plt.tight_layout()
plt.savefig(f"{PLOT_DIR}/psnr_ssim_boxplot.png")
plt.show()

# -----------------------
# Scatter: PSNR vs Entropy
# -----------------------
plt.figure(figsize=(6,4))
plt.scatter(ent, ps, s=8)
plt.xlabel("Entropy")
plt.ylabel("PSNR")
plt.title("PSNR vs Entropy")
plt.tight_layout()
plt.savefig(f"{PLOT_DIR}/psnr_vs_entropy.png")
plt.show()

# -----------------------
# Scatter: SSIM vs Entropy
# -----------------------
plt.figure(figsize=(6,4))
plt.scatter(ent, ss, s=8)
plt.xlabel("Entropy")
plt.ylabel("SSIM")
plt.title("SSIM vs Entropy")
plt.tight_layout()
plt.savefig(f"{PLOT_DIR}/ssim_vs_entropy.png")
plt.show()

# -----------------------
# Save Summary Stats
# -----------------------
summary = {
    "psnr": {"mean": float(ps.mean()), "median": float(np.median(ps)), "std": float(ps.std())},
    "ssim": {"mean": float(ss.mean()), "median": float(np.median(ss)), "std": float(ss.std())},
    "entropy": {"mean": float(ent.mean()), "median": float(np.median(ent)), "std": float(ent.std())},
    "edge_corr": {"mean": float(ec.mean()), "median": float(np.median(ec)), "std": float(ec.std())}
}

with open(f"{PLOT_DIR}/summary_stats.json", "w") as f:
    json.dump(summary, f, indent=2)

print("Saved ALL plots + summary to:", PLOT_DIR)

# Cell D — create montage of best / median / worst fused examples
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import os, csv

# ----------- Load CSV -----------
csv_path = "results/metrics_full_test.csv"
rows = []
with open(csv_path) as f:
    r = csv.reader(f)
    next(r)  # skip header
    for line in r:
        rows.append(line)

# sort by PSNR (column 1)
rows = sorted(rows, key=lambda x: float(x[1]))

# ----------- Output directory (NOW UNDER results/) -----------
OUT_DIR = "results/montage"
os.makedirs(OUT_DIR, exist_ok=True)


def show_and_save_triplet(idx, title, filename):
    """Display and save MRI | CT | Fused triplet."""
    fn = rows[idx][0]

    # Load images
    m = Image.open(os.path.join("dataset_test/mri", fn)).convert("L").resize((256,256))
    c = Image.open(os.path.join("dataset_test/ct", fn)).convert("L").resize((256,256))
    fimg = Image.open(os.path.join("results/test_fused", fn)).convert("L").resize((256,256))

    # Create figure
    plt.figure(figsize=(9,3))
    plt.subplot(1,3,1); plt.imshow(m, cmap="gray"); plt.title("MRI"); plt.axis("off")
    plt.subplot(1,3,2); plt.imshow(c, cmap="gray"); plt.title("CT"); plt.axis("off")
    plt.subplot(1,3,3); plt.imshow(fimg, cmap="gray"); plt.title(title); plt.axis("off")

    # Save figure under results/montage/
    save_path = os.path.join(OUT_DIR, filename)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.show()

    print(f"Saved: {save_path}")


# ----------- Worst example -----------
worst_psnr = float(rows[0][1])
show_and_save_triplet(
    0,
    f"Worst PSNR = {worst_psnr:.2f}",
    f"worst_psnr_{worst_psnr:.2f}.png"
)

# ----------- Median example -----------
mid = len(rows) // 2
median_psnr = float(rows[mid][1])
show_and_save_triplet(
    mid,
    f"Median PSNR = {median_psnr:.2f}",
    f"median_psnr_{median_psnr:.2f}.png"
)

# ----------- Best example -----------
best_psnr = float(rows[-1][1])
show_and_save_triplet(
    -1,
    f"Best PSNR = {best_psnr:.2f}",
    f"best_psnr_{best_psnr:.2f}.png"
)

print("\nAll montages saved inside:", OUT_DIR)